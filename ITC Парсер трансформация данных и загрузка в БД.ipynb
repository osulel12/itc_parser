{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69a7485",
   "metadata": {},
   "source": [
    "## Навигация\n",
    "- **[Функции обработки данных](#Функции-обработки-данных)**\n",
    "- **[Трансформация данных](#Трансформация-данных)**\n",
    "- **[Сборка для Импорт](#Сборка-для-Импорт)**\n",
    "- **[Сборка для Экспорт](#Сборка-для-Экспорт)**\n",
    "- **[Сборка основного датасета](#Сборка-основного-датасета)**\n",
    "- **[Сохраняем данные в БД](#Сохраняем-данные-в-БД)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6080224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path \n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') \n",
    "\n",
    "# Для автоматического закрытия курсора\n",
    "from contextlib import closing\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Сброс ограничений на число столбцов\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e956ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = './.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775456b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_postgres_cred = {'user': os.getenv('USER_NAME_PG'),\n",
    "                      'password': os.getenv('PASSWORD_PG'),\n",
    "                      'host': os.getenv('HOST_PG'),\n",
    "                      'port': os.getenv('PORT_PG'),\n",
    "                      'database': os.getenv('DATABASE_PG')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cdea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация подключений для работы с БД\n",
    "engine = psycopg2.connect(user=dict_postgres_cred['user'],\n",
    "                          password=dict_postgres_cred['password'],\n",
    "                          host=dict_postgres_cred['host'],\n",
    "                          port=dict_postgres_cred['port'],\n",
    "                          database=dict_postgres_cred['database'])\n",
    "conn = create_engine('postgresql://{}:{}@{}:{}/{}'\n",
    "                     .format(dict_postgres_cred['user'], dict_postgres_cred['password'], \n",
    "                             dict_postgres_cred['host'], dict_postgres_cred['port'], dict_postgres_cred['database']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883f1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для переименования всех столбцов\n",
    "def rep(name):\n",
    "    return str(name) \n",
    "\n",
    "def rep_2(name):\n",
    "    return str(name).replace('-', '_') \n",
    "\n",
    "def rep_3(name):\n",
    "    return str(name).replace(' ', '_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2883b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Справочник из БД с единицами измерения\n",
    "query_deizm = f\"\"\"\n",
    "        SELECT * FROM izm\n",
    "        ORDER BY id ASC \n",
    "\"\"\"\n",
    "\n",
    "df_deizm = pd.read_sql(query_deizm, con=engine)\n",
    "df_deizm.rename(columns={'code': 'qty_unit_code','name_rus': 'units_value'}, inplace=True)\n",
    "df_deizm = df_deizm[['qty_unit_code', 'units_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6ff35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_deizm = {}\n",
    "# Заполняем словарь для перехода от ед. изм. itc к общепринятым\n",
    "dict_deizm['Tons'] = 'килограмм'\n",
    "dict_deizm['без размерности'] = 'без размерности'\n",
    "dict_deizm['No quantity'] = 'без размерности'\n",
    "dict_deizm['Pairs'] = 'пара'\n",
    "dict_deizm['Units'] = 'штука'\n",
    "dict_deizm['Cubic meters'] = 'кубический метр'\n",
    "dict_deizm['1000 meters'] = 'метр'\n",
    "dict_deizm['1000 square meters'] = 'квадратный метр'\n",
    "dict_deizm['Carats'] = 'карат'\n",
    "dict_deizm['Mega watt hours'] = '1000 кВаттЧас'\n",
    "dict_deizm['Thousands'] = '1000 штук'\n",
    "dict_deizm['Mixed'] = 'без размерности'  \n",
    "dict_deizm['Number of packages'] = '1 пачка'\n",
    "dict_deizm['Dozen'] = 'дюжина'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edce1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словаврь для партнера\n",
    "query_country_add = f\"\"\"\n",
    "\n",
    "SELECT code, name_itc FROM add\n",
    "\n",
    "\"\"\"\n",
    "df_country_add = pd.read_sql(query_country_add, con=engine)\n",
    "\n",
    "# Подготовим колонку для мержа\n",
    "df_country_add['test_name'] = df_country_add.name_itc.apply(lambda x: x.replace(',', ''))\n",
    "\n",
    "# Чистим данные\n",
    "df_country_add.drop_duplicates(subset=['name_itc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd2ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для присовения кодов Репортеру\n",
    "dict_partner_code = {}\n",
    "dct_itc_and_test_name = {}\n",
    "for code_itc, name_test in zip(list(df_country_add.code), list(df_country_add.test_name)):\n",
    "    if name_test not in dict_partner_code:\n",
    "        dict_partner_code[name_test] = code_itc\n",
    "    else:\n",
    "        continue\n",
    "# Для сопоставления наших названий стран и стран из itc\n",
    "for itc_name, name_test in zip(list(df_country_add.name_itc), list(df_country_add.test_name)):\n",
    "    if name_test not in dct_itc_and_test_name:\n",
    "        dct_itc_and_test_name[name_test] = itc_name\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f88b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_need_tnved_code() -> dict:\n",
    "    \"\"\"\n",
    "    Возвращает набор необходимых кодов ТНВЭД\n",
    "\n",
    "    :return: словарь с кодами (пока что на 6 знаках 'code_6')\n",
    "    \"\"\"\n",
    "   \n",
    "    dict_return = {'code_6': []}\n",
    "    with conn.connect() as connection:\n",
    "        rez_query = connection.execute(\"\"\"SELECT DISTINCT(LEFT(code,6)) \n",
    "                                               FROM ed \n",
    "                                               WHERE type = 10 AND prod_type = 'apk' AND LEFT(code, 2)::int > 24\"\"\")\n",
    "    for code in rez_query.fetchall():\n",
    "        code_cleare = code[0]\n",
    "        dict_return['code_6'].append(code_cleare)\n",
    "    return dict_return\n",
    "\n",
    "dict_need_tnved_code_apk = get_need_tnved_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71074e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Года с атрибутом Mirror data\n",
    "# Их мы исключаем при сборке\n",
    "if os.path.exists('json_mirror_data.json'):\n",
    "    with open('json_mirror_data.json', encoding='utf-8') as fl:\n",
    "        js = json.load(fl)\n",
    "else:\n",
    "    js = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258f4d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Albania': ['2023']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea6456e",
   "metadata": {},
   "source": [
    "# Функции обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21fcfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_value_build(path_values: str, type_operation: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Собирает все файлы в один датафрейм для переданного направления торговли\n",
    "    по переданному пути\n",
    "    \n",
    "    :param path_values: путь к файлам для TRADE_VALUE\n",
    "    \n",
    "    :param type_operation: тип операции (импорт - 1 или экспорт - 2)\n",
    "    \n",
    "    :return: очищенный датафрейм с данными по TRADE_VALUE\n",
    "    \"\"\"\n",
    "    # Объект типа Path для TRADE_VALUE\n",
    "    way_pah_values = Path(path_values)\n",
    "\n",
    "    # Пустой датафрейм для сборки всех значений trade_value\n",
    "    void_df_value = pd.DataFrame()\n",
    "\n",
    "    # Сбор файлов trade_value\n",
    "    for i in tqdm(way_pah_values.glob(\"**/Tra*.txt\")):\n",
    "\n",
    "        if flag_and_in_reporter_name:\n",
    "            # Если в названии репортера присутствует _and_ : Antigua_and_Barbuda\n",
    "            reporter = ' and '.join(str(i).split('_between_')[1].split('_and_')[:2]).replace('_', ' ').replace('  ', ' ')\n",
    "            partner = ' and '.join(str(i).split('_between_')[1].split('_and_')[2:]).replace('.txt', '').replace('_', ' ').replace('  ', ' ')  \n",
    "        else:\n",
    "            # Если репортер без _and_ : Cabo_Verde\n",
    "            reporter = str(i).split('_between_')[1].split('_and_')[0].replace('_', ' ').replace('  ', ' ')\n",
    "            partner = ' and '.join(str(i).split('_between_')[1].split('_and_')[1:]).replace('.txt', '').replace('_', ' ').replace('  ', ' ')\n",
    "\n",
    "        # Если есть зеркальные года, сохраняеим их\n",
    "        lst_query = js[reporter] if reporter in js else []\n",
    "\n",
    "        temp_df = pd.read_table(i, dtype={'Product code': 'str'})\n",
    "\n",
    "        # Получаем нужное количество колонок\n",
    "        need_max_year = max([int(i.split(' in ')[-1]) for i in temp_df.columns.tolist() if ' in ' in i])\n",
    "        for temp in range(len(list(temp_df.columns))):\n",
    "            if f'-Value in {need_max_year}' in list(temp_df.columns)[temp]:\n",
    "                temp_number_columns = temp + 1\n",
    "                break\n",
    "        if partner == 'World':\n",
    "            temp_df = temp_df.drop(columns=list(temp_df.iloc[:, 2:16].columns)).iloc[:, 0:14]\n",
    "        else:\n",
    "            temp_df = temp_df.iloc[:,0:temp_number_columns]\n",
    "\n",
    "        # Расплавляем датасет\n",
    "        temp_df = temp_df.melt(id_vars=['Product code', 'Product label'])\n",
    "        temp_df.rename(columns = rep_3, inplace=True)\n",
    "        \n",
    "        # Отсекаем не нужное\n",
    "        temp_df = temp_df.query('value > 0 and Product_code != \"TOTAL\"')\n",
    "        temp_df = temp_df[\n",
    "            (temp_df['Product_code'].str[:2].astype(int) <= 24) |\n",
    "            (temp_df['Product_code'].str[:2].astype(int) == 31) |\n",
    "            (temp_df['Product_code'].str[:6].isin(dict_need_tnved_code_apk['code_6']))\n",
    "            ]\n",
    "        temp_df.fillna(0, inplace=True)\n",
    "\n",
    "       \n",
    "        # Добавляем столбцы\n",
    "        temp_df = temp_df.assign(reporter_country = reporter ,partner_country = partner, trade_flow_code = type_operation, \n",
    "                                classification='HS', update_date=datetime.now().strftime('%Y-%m-%d'))\n",
    "        temp_df['year_transaction'] = temp_df.variable.apply(lambda x: x.split(' in ')[1])\n",
    "        temp_df = temp_df.query('year_transaction not in @lst_query')\n",
    "        temp_df['period'] = temp_df.year_transaction.apply(lambda x: datetime.strptime('01-01-' + x, '%d-%m-%Y'))\n",
    "        temp_df['aggregate_level'] = 6\n",
    "        temp_df['flag'] = 0\n",
    "        temp_df['plus'] = 0\n",
    "        temp_df['load_mark'] = 1\n",
    "        temp_df['value'] = temp_df.value.mul(1000)\n",
    "        void_df_value = pd.concat((void_df_value, temp_df))\n",
    "\n",
    "    # Создаем колонку для мержа\n",
    "    void_df_value['test_name'] = void_df_value.partner_country.apply(lambda x: x)\n",
    "    # Удаляем лишнее\n",
    "    void_df_value.drop(columns='variable', inplace=True)\n",
    "\n",
    "    # Мержим наш void_df_value с COUNTRY_ADD\n",
    "    df_merge = void_df_value.merge(df_country_add, how='left',  on='test_name')\n",
    "\n",
    "    df_merge.rename(columns={'code': 'partner_code'}, inplace=True)\n",
    "    # В зависимости от страны проставляем код\n",
    "    df_merge['reporter_code'] = df_merge.reporter_country.apply(lambda x: dict_partner_code[x])\n",
    "    \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c51319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_not_download_file(type_flow: str, path_values: str, path_quantities: str) -> dict:\n",
    "    \"\"\"\n",
    "    Проверяет, всели файлы по Quantities мы скачали исходя из файлов TRADE_VALUE\n",
    "    Если были скачены не все, функция вернет словарь с партнерами, которые отсутствуют\n",
    "    \n",
    "    :param type_flow: тип операции (импорт или экспорт)\n",
    "    \n",
    "    :param path_values: путь к файлам для TRADE_VALUE\n",
    "    \n",
    "    :param path_quantities: путь к файлам для Quantities\n",
    "    \n",
    "    :return: словарь со странами, которые мы не скачали, если такие есть\n",
    "    \"\"\"\n",
    "\n",
    "    # Проверка не скаченных файлов\n",
    "    # Если таких нет, докачайте их\n",
    "    dct_error_country = {'type_flow': type_flow,\n",
    "                         'reporter_name': '', 'list_partner': []}\n",
    "\n",
    "\n",
    "    l_values = [str(i).split('\\\\')[-1] for i in Path(path_values).glob('**/Tra*.txt')]\n",
    "    l_quantities = [str(i).split('\\\\')[-1] for i in Path(path_quantities).glob('**/Tra*.txt')]\n",
    "    for i in l_values:\n",
    "        if i not in l_quantities:\n",
    "            # Получаем название репортера и партнера\n",
    "            if flag_and_in_reporter_name:\n",
    "                # Если в названии репортера присутствует _and_ : Antigua_and_Barbuda\n",
    "                reporter = ' and '.join(str(i).split('_between_')[1].split('_and_')[:2]).replace('_', ' ').replace('  ', ' ')\n",
    "                partner = ' and '.join(str(i).split('_between_')[1].split('_and_')[2:]).replace('.txt', '').replace('_', ' ').replace('  ', ' ')  \n",
    "            else:\n",
    "                # Если репортер без _and_ : Cabo_Verde\n",
    "                reporter = str(i).split('_between_')[1].split('_and_')[0].replace('_', ' ').replace('  ', ' ')\n",
    "                partner = ' and '.join(str(i).split('_between_')[1].split('_and_')[1:]).replace('.txt', '').replace('_', ' ').replace('  ', ' ')\n",
    "            # Заполняем словарь не докаченных файлов\n",
    "            dct_error_country['reporter_name'] = dct_itc_and_test_name[reporter]\n",
    "            if dct_itc_and_test_name[partner] not in dct_error_country['list_partner']:\n",
    "                dct_error_country['list_partner'].append(dct_itc_and_test_name[partner])\n",
    "\n",
    "\n",
    "            print(f\"{i} отсутствуют\")\n",
    "    return dct_error_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e726570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def quantities_build(type_operation: str, path_values: str, path_quantities: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Собирает все файлы в один датафрейм для переданного направления торговли\n",
    "    по переданному пути\n",
    "    \n",
    "    :param type_operation: тип операции (импорт или экспорт)\n",
    "    \n",
    "    :param path_values: путь к файлам для TRADE_VALUE\n",
    "    \n",
    "    :param path_quantities: путь к файлам для Quantities\n",
    "    \n",
    "    :return: очищенный датафрейм с данными по Quantities\n",
    "    \"\"\"\n",
    "    # Создаем объект типа Path\n",
    "    way_pah_quantities = Path(path_quantities)\n",
    "\n",
    "    # Пустой датафрейм для Quantities\n",
    "    void_df_quantities = pd.DataFrame()\n",
    "\n",
    "    dct_error = check_not_download_file(type_operation, path_values, path_quantities)\n",
    "    # Сбор файлов Quantities\n",
    "    for i in tqdm(way_pah_quantities.glob('**/Tra*.txt')):\n",
    "        if flag_and_in_reporter_name:\n",
    "            # Если в названии репортера присутствует _and_ : Antigua_and_Barbuda\n",
    "            reporter = ' and '.join(str(i).split('_between_')[1].split('_and_')[:2]).replace('_', ' ').replace('  ', ' ')\n",
    "            partner = ' and '.join(str(i).split('_between_')[1].split('_and_')[2:]).replace('.txt', '').replace('_', ' ').replace('  ', ' ')  \n",
    "        else:\n",
    "            # Если репортер без _and_ : Cabo_Verde\n",
    "            reporter = str(i).split('_between_')[1].split('_and_')[0].replace('_', ' ').replace('  ', ' ')\n",
    "            partner = ' and '.join(str(i).split('_between_')[1].split('_and_')[1:]).replace('.txt', '').replace('_', ' ').replace('  ', ' ')\n",
    "\n",
    "\n",
    "        temp_df = pd.read_table(i, dtype={'Product code': 'str'})\n",
    "\n",
    "        # Если был скачен не тот фалй (value вместо quantities)\n",
    "        # То мы фиксируем его в словаре ошибок, для дальнейшей обработки\n",
    "        if len([i for i in temp_df.columns.tolist() if '-Value in ' in i]) > 0:\n",
    "            print(f'Ошибка в партнере: {partner}')\n",
    "            if dct_itc_and_test_name[partner] not in dct_error['list_partner']:\n",
    "                dct_error['list_partner'].append(dct_itc_and_test_name[partner])\n",
    "            print(f\"Удаляем {i}\")    \n",
    "            i.unlink()\n",
    "        else:\n",
    "            # Если есть зеркальные года, сохраняеим их\n",
    "            lst_query = js[reporter] if reporter in js else []\n",
    "            #Считаем нужное кол-во столбцов(максимальный и минимальный года)\n",
    "            need_max_year = max([int(i.split(' in ')[-1]) for i in temp_df.columns.tolist() if ' in ' in i])\n",
    "            need_min_year = min([int(i.split(' in ')[-1]) for i in temp_df.columns.tolist() if ' in ' in i])\n",
    "            for temp in range(len(list(temp_df.columns))):\n",
    "                if f'-Quantity in {need_max_year}' in list(temp_df.columns)[temp]:\n",
    "                    temp_number_columns = temp + 2\n",
    "                    break\n",
    "\n",
    "            if partner == 'World':\n",
    "                temp_df = temp_df.drop(columns=list(temp_df.iloc[:, 2:28].columns)).iloc[:, 0:26]\n",
    "            else:\n",
    "                temp_df = temp_df.iloc[:,0:temp_number_columns] #26\n",
    "\n",
    "            # Расплавляем датасет\n",
    "            temp_df = temp_df.melt(id_vars=['Product code', 'Product label'])\n",
    "            temp_df.rename(columns = rep_3, inplace=True)\n",
    "\n",
    "            # Отсекаем не нужное\n",
    "            temp_df.fillna(0, inplace=True)\n",
    "            temp_df = temp_df[(temp_df['value'] != 0) & (temp_df['Product_code'] != \"TOTAL\")]\n",
    "            temp_df = temp_df[\n",
    "                (temp_df['Product_code'].str[:2].astype(int) <= 24) |\n",
    "                (temp_df['Product_code'].str[:2].astype(int) == 31) |\n",
    "                (temp_df['Product_code'].str[:6].isin(dict_need_tnved_code_apk['code_6']))\n",
    "                ]\n",
    "            \n",
    "            \n",
    "            temp_df = temp_df.assign(reporter_country = reporter ,partner_country = partner)\n",
    "\n",
    "            # Создаем два датасета, первый для названия измерений\n",
    "            # Второй для самих измерений\n",
    "            temp_df['bool_unit'] = temp_df.variable.apply(lambda x: True if '-Unit' in x else False)\n",
    "            temp_df['bool_quantity'] = temp_df.variable.apply(lambda x: True if '-Unit' not in x else False)\n",
    "            df_unit_tmp = temp_df.loc[temp_df.bool_unit]\n",
    "            df_quantity_tmp = temp_df.loc[temp_df.bool_quantity]\n",
    "\n",
    "            # Формируем лист из \"якорей\" для опеределения года в датасете с названиями измерений\n",
    "            list_unit_from_key = []\n",
    "            for i in list(df_unit_tmp.variable.unique()):\n",
    "                if i.split('-U')[1] not in list_unit_from_key:\n",
    "                    list_unit_from_key.append(i.split('-U')[1])\n",
    "            # Формируем списко для последующего преобразования\n",
    "            dict_unit = {}\n",
    "            year = need_min_year\n",
    "            for j in list_unit_from_key:\n",
    "                if j not in dict_unit:\n",
    "                    value_sum = int(j.split('.')[1]) if len(j.split('.')) > 1 else 0\n",
    "                    year_tmp = value_sum + year\n",
    "                    dict_unit[j] = str(year_tmp)\n",
    "\n",
    "            # Чистим и преобразуем датафрейм с названиями измерений к дальнейшему мержу\n",
    "            df_unit_tmp['year_transaction'] = df_unit_tmp.variable.apply(lambda x: dict_unit[str(x).split('-U')[1]])\n",
    "            df_unit_tmp = df_unit_tmp.query('year_transaction not in @lst_query')\n",
    "            df_unit_tmp.rename(columns={'value': 'units_value'}, inplace=True)\n",
    "            df_unit_tmp = df_unit_tmp[['Product_code', 'Product_label', 'units_value', 'reporter_country', \n",
    "                                                      'partner_country', 'year_transaction']]\n",
    "\n",
    "            # Чистим и преобразуем датафрейм с измерениями к дальнейшему мержу\n",
    "            df_quantity_tmp.rename(columns={'variable': 'year_transaction'}, inplace=True)\n",
    "            df_quantity_tmp['year_transaction'] =  df_quantity_tmp.year_transaction.apply(lambda x: x.split(' in ')[1])\n",
    "            df_quantity_tmp = df_quantity_tmp.query('year_transaction not in @lst_query')\n",
    "\n",
    "            # Мержим датасеты\n",
    "            df_merge_quantities = df_quantity_tmp.merge(df_unit_tmp, on=['Product_code', 'year_transaction','reporter_country',\n",
    "                                                             'partner_country'], how='left')\n",
    "            # Редактируем наименования партнеров для мержа\n",
    "            void_df_quantities = pd.concat((void_df_quantities, df_merge_quantities))\n",
    "    \n",
    "    # Сохраняем ошибки в файл       \n",
    "    with open(f'{type_operation}_error_itc.json', 'w', encoding='utf-8') as file_json:\n",
    "        json.dump(dct_error, file_json, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    return void_df_quantities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d98567c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для проверки загрузки данных в БД и их очистку\n",
    "class Check_zero_in_db_value:\n",
    "    \n",
    "    def __init__(self, reporter_code, engine_class, df):\n",
    "        \"\"\"\n",
    "        reporter_code: код репортера\n",
    "        engine_class: движок подключения к БД\n",
    "        df: полученный датафрейм на этапе обработки данных\n",
    "        \"\"\"\n",
    "        self.reporter_code = reporter_code\n",
    "        self.engine_class = engine_class\n",
    "        self.df = df\n",
    "    \n",
    "    def get_count_rows(self, need_year=None):\n",
    "        \"\"\"\n",
    "        need_year: минимально максимальный год из ранее загруженных данных в БД\n",
    "        return: количество строк по конкретному репортеру в БД\n",
    "        \"\"\"\n",
    "        # Если такой год присутствует, то вернуть рассчет без его учета\n",
    "        # Для корректной валидации\n",
    "        if need_year:\n",
    "            return pd.read_sql(f\"\"\"SELECT COUNT(year) as count_rows \n",
    "                                   FROM tc \n",
    "                                   WHERE reporter_code = {self.reporter_code} AND year > {need_year}\"\"\",\n",
    "                            con=self.engine_class).count_rows[0]\n",
    "        # Если данных нет или они полностью совпадают, то посчитать все строки\n",
    "        else:\n",
    "            return pd.read_sql(f\"\"\"SELECT COUNT(year) as count_rows \n",
    "                                   FROM tc \n",
    "                                   WHERE reporter_code = {self.reporter_code}\"\"\",\n",
    "                            con=self.engine_class).count_rows[0]\n",
    "    \n",
    "    def get_min_year_in_db(self, need_year):\n",
    "        \"\"\"\n",
    "        need_year: минимальный год из датафрейма\n",
    "        return: максимальный год из всех годов, которые меньше need_year или need_year если таковых нет\n",
    "        \"\"\"\n",
    "        year_list = pd.read_sql(f\"\"\"SELECT DISTINCT(year) AS year \n",
    "                                    FROM tc\n",
    "                                    WHERE reporter_code = {self.reporter_code} AND year < {need_year}\n",
    "                                    ORDER BY year\"\"\",\n",
    "                        con=self.engine_class).year\n",
    "        return need_year if year_list.shape[0]  == 0 else year_list.max()\n",
    "    \n",
    "    def get_min_year_in_df(self):\n",
    "        \"\"\"\n",
    "        return: минимальный год из датафрейма\n",
    "        \"\"\"\n",
    "        return min([int(y) for y in self.df.year.unique()])\n",
    "        \n",
    "    def delete_need_value(self):\n",
    "        \"\"\"\n",
    "        return: True если очистка прошла успешно, иначе False\n",
    "        \"\"\"\n",
    "        if (self.get_min_year_in_df() == self.get_min_year_in_db(self.get_min_year_in_df())) or \\\n",
    "            (self.get_min_year_in_db(self.get_min_year_in_df()) > self.get_min_year_in_df()):\n",
    "                \n",
    "            with self.engine_class.cursor() as cr:\n",
    "                cr.execute(f\"\"\"DELETE FROM tc \n",
    "                               WHERE reporter_code = {self.reporter_code}\"\"\")\n",
    "                self.engine_class.commit()\n",
    "            return self.get_count_rows() == 0\n",
    "        \n",
    "        elif self.get_min_year_in_db(self.get_min_year_in_df()) < self.get_min_year_in_df():\n",
    "\n",
    "            with self.engine_class.cursor() as cr:\n",
    "                cr.execute(f\"\"\"DELETE FROM tc \n",
    "                               WHERE reporter_code = {self.reporter_code} \n",
    "                               AND year > {self.get_min_year_in_db(self.get_min_year_in_df())}\"\"\")\n",
    "                self.engine_class.commit()\n",
    "            return self.get_count_rows(self.get_min_year_in_db(self.get_min_year_in_df())) == 0\n",
    "        \n",
    "    def check_value(self):\n",
    "        if self.get_count_rows() == 0:\n",
    "            return True\n",
    "        return self.delete_need_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ceaff8",
   "metadata": {},
   "source": [
    "# Трансформация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa06cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для формирования путей к нужным папкам с файлами\n",
    "type_flow_import = 'Imports'\n",
    "type_flow_export = 'Exports'\n",
    "value = 'Values'\n",
    "qty = 'Quantities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a9d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Cabo Verde\", \"South Africa\", \"Botswana\", \"Cambodia\", \"Guatemala\", \"Saudi Arabia\", \"Slovakia\", \"Slovenia\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b07e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подставить нужного репортера\n",
    "reporter_name = \"Slovenia\"\n",
    "# Флаг. Если в имени репортера присутствует and (Antigua_and_Barbuda) Присвоить значение True, иначе False\n",
    "flag_and_in_reporter_name = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a57a6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "# Проверка количесвта стран для экспорта (только на шаге парсинга TRADE_VALUE)\n",
    "if os.path.exists('Imports_res.json'):\n",
    "    with open('Imports_res.json', encoding='utf-8') as fl:\n",
    "        js_imp = json.load(fl)\n",
    "    if reporter_name in js_imp:\n",
    "        print(len(js_imp[reporter_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92eda6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "# Проверка количесвта стран для экспорта (только на шаге парсинга TRADE_VALUE)\n",
    "if os.path.exists('Exports_res.json'):\n",
    "    with open('Exports_res.json', encoding='utf-8') as fl:\n",
    "        js_exp = json.load(fl)\n",
    "    if reporter_name in js_exp:\n",
    "        print(len(js_exp[reporter_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6ab1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Imports' = 1 'Exports' = 2\n",
    "# Ссылки для Импорта\n",
    "path_values_import = os.path.join(os.getcwd(), f\"\"\"{reporter_name}_{type_flow_import}_{value}\"\"\")\n",
    "path_quantities_import = os.path.join(os.getcwd(), f\"\"\"{reporter_name}_{type_flow_import}_{qty}\"\"\")\n",
    "\n",
    "# Ссылки для Экспорта\n",
    "path_values_export = os.path.join(os.getcwd(), f\"\"\"{reporter_name}_{type_flow_export}_{value}\"\"\")\n",
    "path_quantities_export = os.path.join(os.getcwd(), f\"\"\"{reporter_name}_{type_flow_export}_{qty}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0350c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем скаченные дубликаты, если такие есть\n",
    "# Для trade_value Imports\n",
    "for val in Path(path_values_import).glob(\"**/*(1)*.txt\"):\n",
    "    print(val)\n",
    "    val.unlink()\n",
    "\n",
    "# Для quantities Imports\n",
    "for quant in Path(path_quantities_import).glob(\"**/*(1)*.txt\"):\n",
    "    print(quant)\n",
    "    quant.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3085f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем скаченные дубликаты, если такие есть\n",
    "# Для trade_value Exports\n",
    "for val in Path(path_values_export).glob(\"**/*(1)*.txt\"):\n",
    "    print(val)\n",
    "    val.unlink()\n",
    "\n",
    "# Для quantities Exports\n",
    "for quant in Path(path_quantities_export).glob(\"**/*(1)*.txt\"):\n",
    "    print(quant)\n",
    "    quant.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e362b6",
   "metadata": {},
   "source": [
    "# Сборка для Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f43f06c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:19, 11.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Датафрейм Импорт tarde_value\n",
    "df_trade_value_import = trade_value_build(path_values_import, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790fc6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:38,  5.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Датафрейм Импорт quantities\n",
    "df_quantities_import = quantities_build(type_flow_import, path_values_import, path_quantities_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5afd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем единый датасет trade_value + quantities\n",
    "df_full_import = df_trade_value_import.merge(df_quantities_import, on=['Product_code', 'year_transaction','reporter_country',\n",
    "                                                     'partner_country'], how='left', suffixes=('_trade', '_netweight'))\n",
    "\n",
    "df_full_import = df_full_import[['Product_code', 'Product_label', 'value_trade', 'reporter_country', 'partner_country', 'trade_flow_code',\n",
    "                   'classification', 'update_date', 'year_transaction', 'period', 'aggregate_level', 'flag', 'plus', 'load_mark',\n",
    "                   'partner_code', 'reporter_code', 'name_itc', 'value_netweight', 'units_value']]\n",
    "\n",
    "df_full_import.rename(columns={'Product_code': 'commodity_code', 'value_trade': 'trade_value', 'year_transaction': 'year',\n",
    "                        'value_netweight': 'netweight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7468db84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tons', nan], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим, какие измерения попали в датасет\n",
    "df_full_import.units_value.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f0cb8",
   "metadata": {},
   "source": [
    "# Сборка для Экспорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bbe9719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:16, 13.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Датафрейм Экспорт tarde_value\n",
    "df_trade_value_export = trade_value_build(path_values_export, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f420866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:36,  6.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Датафрейм Экспорт quantities\n",
    "df_quantities_export = quantities_build(type_flow_export, path_values_export, path_quantities_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75213c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем единый датасет trade_value + quantities\n",
    "df_full_export = df_trade_value_export.merge(df_quantities_export, on=['Product_code', 'year_transaction','reporter_country',\n",
    "                                                     'partner_country'], how='left', suffixes=('_trade', '_netweight'))\n",
    "\n",
    "df_full_export = df_full_export[['Product_code', 'Product_label', 'value_trade', 'reporter_country', 'partner_country', 'trade_flow_code',\n",
    "                   'classification', 'update_date', 'year_transaction', 'period', 'aggregate_level', 'flag', 'plus', 'load_mark',\n",
    "                   'partner_code', 'reporter_code', 'name_itc', 'value_netweight', 'units_value']]\n",
    "\n",
    "df_full_export.rename(columns={'Product_code': 'commodity_code', 'value_trade': 'trade_value', 'year_transaction': 'year',\n",
    "                        'value_netweight': 'netweight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ab8ba87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tons', nan], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим, какие измерения попали в датасет\n",
    "df_full_export.units_value.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088c1d8",
   "metadata": {},
   "source": [
    "### [⬅ Навигация](#Навигация)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd82e37",
   "metadata": {},
   "source": [
    "# Сборка основного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af38ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем все данные в один датафрейм\n",
    "df_all_data = pd.concat((df_full_import, df_full_export))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "456ece04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_d_izm(units: pd.Series, netweight: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Получает на вход две серии и исходя из условия получает приведенную к нужному формату qty\n",
    "\n",
    "    :param units: колонку(серию) с типами измерения\n",
    "\n",
    "    :param netweight: колонку(серию) со значением величины (вес)\n",
    "\n",
    "    :return: преобразованную серию\n",
    "    \"\"\"\n",
    "    coefficients = np.where(units.isin(['1000 meters', '1000 square meters']), 1000, 1)\n",
    "    return netweight * coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11c0dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем пропуски \n",
    "df_all_data['netweight'] = df_all_data.netweight.fillna(0)\n",
    "df_all_data['units_value'] = df_all_data.units_value.fillna('без размерности')\n",
    "\n",
    "\n",
    "# Заменяем на поправленные единицы измерения\n",
    "df_all_data['netweight'] = fix_d_izm(df_all_data['units_value'], df_all_data['netweight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "796bc277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['килограмм', 'без размерности'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Меняем названия величин измерений на русские\n",
    "df_all_data['units_value'] = df_all_data.units_value.map(dict_deizm)\n",
    "df_all_data.units_value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36f275dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разносим данные по qty и netweight\n",
    "df_all_data['qty'] = np.where(df_all_data.units_value != 'килограмм', df_all_data.netweight, 0)\n",
    "df_all_data['netweight'] = np.where(df_all_data.units_value == 'килограмм', df_all_data.netweight * 1000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adc1f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data = df_all_data.merge(df_deizm, on='units_value', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e9caf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем нужные столбцы в нужном порядке\n",
    "df_all_data = df_all_data[['classification', 'year', 'period', 'aggregate_level', 'trade_flow_code', 'reporter_code', \n",
    "                       'partner_code', 'commodity_code', 'qty_unit_code', 'qty', 'netweight', \n",
    "                       'trade_value', 'flag', 'plus', 'load_mark', 'update_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88fbfcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184134, 19)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_data['update_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "df_all_data['customs_proc_code'] = 'C00'\n",
    "df_all_data['mode_of_transport_code'] = '0'\n",
    "df_all_data['partner_code_2nd'] = 0\n",
    "df_all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da84c78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification            0\n",
       "year                      0\n",
       "period                    0\n",
       "aggregate_level           0\n",
       "trade_flow_code           0\n",
       "reporter_code             0\n",
       "partner_code              0\n",
       "commodity_code            0\n",
       "qty_unit_code             0\n",
       "qty                       0\n",
       "netweight                 0\n",
       "trade_value               0\n",
       "flag                      0\n",
       "plus                      0\n",
       "load_mark                 0\n",
       "update_date               0\n",
       "customs_proc_code         0\n",
       "mode_of_transport_code    0\n",
       "partner_code_2nd          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1dc199",
   "metadata": {},
   "source": [
    "### [⬅ Навигация](#Навигация)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e438924",
   "metadata": {},
   "source": [
    "# Сохраняем данные в БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2391f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем код репортера\n",
    "reporter_code_for_check = df_all_data.reporter_code.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84d7ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '2022',\n",
       " '2023',\n",
       " '2024']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Перед записью в БД проверим года\n",
    "sorted(df_all_data.year.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a752e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем репортера 705\n",
      "2013, количество строк: 13864\n",
      "2014, количество строк: 13837\n",
      "2015, количество строк: 13868\n",
      "2016, количество строк: 14457\n",
      "2017, количество строк: 15232\n",
      "2018, количество строк: 15296\n",
      "2022, количество строк: 17114\n",
      "2023, количество строк: 17114\n",
      "2019, количество строк: 15480\n",
      "2020, количество строк: 15594\n",
      "2021, количество строк: 16402\n",
      "2024, количество строк: 15876\n"
     ]
    }
   ],
   "source": [
    "# Запись в партиции БД\n",
    "if Check_zero_in_db_value(reporter_code_for_check, engine, df_all_data).check_value():\n",
    "    print(f'Загружаем репортера {reporter_code_for_check}')\n",
    "    for year_cycle in df_all_data.year.unique().tolist():\n",
    "\n",
    "        df_data_in_bd = df_all_data.query('year == @year_cycle')\n",
    "        print(f'{year_cycle}, количество строк: {df_data_in_bd.shape[0]}')\n",
    "        df_data_in_bd.to_sql(f'_{year_cycle}', \n",
    "                             con=conn, \n",
    "                             schema='', \n",
    "                             if_exists='append', index=False)\n",
    "else:\n",
    "    print('Старые данные не очищенны')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e842503f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Check_zero_in_db_value(reporter_code_for_check, engine, df_all_data).get_min_year_in_db(df_all_data.year.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32d1d704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если данные уже были в базе передать в параметр get_count_rows год\n",
    "# Пример, у нас в датафрейме минимальный год 2011, но в базе есть 2009 и 2010 года (их мы не обновляем)\n",
    "# Для корретной валидации нужно передать 2010 год(максимальный год, который есть в базе, но нет в датафрейме)\n",
    "df_all_data.shape[0] ==  Check_zero_in_db_value(reporter_code_for_check, engine, df_all_data).get_count_rows(2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82d443",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9580f3b1",
   "metadata": {},
   "source": [
    "### [⬅ Навигация](#Навигация)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
