# itc_parser_ae
Перед использованием важно установить WebDriver. В нашем случае это **chromedriver**

### Инструкция
- [ ] Проверьте версию своего браузера, для этого введите в адресной строке ```chrome://version/```
- [ ] Далее переходим на [сайт](https://googlechromelabs.github.io/chrome-for-testing/#stable) и качаем свою версию браузера. Если такой нет, то качаем ту, с которой совпадает первая цифра.
- [ ] Когда мы скачали *chromedriver_win64.zip*, распакуем архив на диск *C:/* и переименуем, чтобы путь выглядел так: ```C:\chromedriver\chromedriver.exe```
- [ ] Далее нам необходиом добавить путь ```C:\chromedriver\``` в переменные среды (свойства системы) параметр **Path**. Это нужно сделать в двух местах (Переменные среды пользователя и системные переменные)
- [ ] После добавления нажимаем клавиши ```Win + R``` и вводим команду ```cmd``` в открывшемся окне вводим ```Path```. В списке пуией должен появиться ```C:\chromedriver\```. Если нет, то перезапустите ПК.
## Структура файлов
1. main.py - основной файл из которого происходит запуск скрипта и изменение переменных
2. class_parser.py - содержит класс реализующий логики парсинга
3. .env - файл с кредами и подключениями
4. logger_file.py - содержит настройку записи логов в файл
5. config.py - содержит словарь id и имен тэгов необходимых для парсинга
6. Файлы *.ipynb - содержат скрипты трансформации и загрузки скаченных данных в БД


# main py
Для управления процессом парсинга в файле main.py можно менять значения следующих переменных
```python
# tariff - значит парсим тарифные линии
# not_tariff - значит парсим данные на 6 знаках
variant_parser = 'not_tariff'

# Imports_error_itc.json - для ошибок в импорте
# Exports_error_itc.json - для ошибок в экспорте
file_fixe_name = 'Imports_error_itc.json'
```
*variant_parser* - на скольки знаках мы выкачиваем данные

*file_fixe_name* - если случится ошибка в файле (скачался не тот файл), указать json соответствующий направлению торговли

Блок после *input_user_text* отвечает за тип скачивания данных, в прописанных там циклах необходимо подставить те значения стран, которые нам нужны и те 
*type_flow* и *qty_or_value*, которые необходимы. По умолчанию идут все полные списки, за исключением стран репортеров

**ПРИ ПЕРВОМ ЗАПУСКЕ НОВЫМ ПОЛЬЗОВАТЕЛЕМ**
передать в *flag_insert_user* значение ```True```, чтобы записать пользователя в БД

# Структура .env 
Используемый env файл содержит следующую структуру

``` python
# Патерн названия скачивания файла на 6 знаках
PATERN_FILE="Trade_Map_-_Existing_and_potential_trade_between_{}_and_{}.txt"
# Патерн названия скачивания файла на 6 знаках
PATERN_FILE_TARIFF_LINE="Trade_Map_-_Bilateral_trade_between_{}_and_{}.txt"
PH_DESTINATION='директория\куда\будет\склонирован\парсер'
ITC_LOGIN='ваш логи от itc'
ITC_PASSWORD='ваш пароль от itc'
CHAT_ID='чат id в ETL bot для того пользователя, который будет запускать скрипт'
BOT_TOKEN_ETL_BOT='токен бота'
HOST_PG='хост используемой БД'
PORT_PG='порт используемой БД'
USER_NAME_PG='логин БД'
PASSWORD_PG='пароль БД'
DATABASE_PG='имя БД'
```

# Файлы *.ipynb
Просто следовать инструкции и последовательно запускать ячейки создавая необходимы словари и переменные.

Основная работа идет в блоке **Трансформация данных**.
Здесь нам необходимо менять параметр ```reporter_name``` исходя из скаченных стран, а дальше проходить последующие ячейки заново.
Так же обращать внимание на принты при получении датафреймов, так как там будут выводиться файлы, в которых были допущены ошибки или которые необходимо до качать
Для этого нужно запустить файл *main.py* и ввести ```0``` дальше скачаются только исправляемые файлы.


